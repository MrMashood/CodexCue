{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preparation:"
      ],
      "metadata": {
        "id": "8NeeS4vyV0c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "data = pd.read_csv(\"/content/emails.csv\")\n",
        "\n",
        "X = data.drop(columns=['Prediction'])\n",
        "y = data['Prediction']\n",
        "\n",
        "X_numeric = X.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_numeric)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wu-3WUYHNAAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Selectionb and Training:"
      ],
      "metadata": {
        "id": "2s4YkF44V4no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "svm = SVC()\n",
        "\n",
        "models = [logistic_regression, decision_tree, svm]\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    print(f\"{model.__class__.__name__} Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cem_gqHpSqWm",
        "outputId": "113b7deb-ba24-4ce4-cd75-b56b10b9b1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression Accuracy: 0.970048309178744\n",
            "DecisionTreeClassifier Accuracy: 0.9217391304347826\n",
            "SVC Accuracy: 0.9468599033816425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Evaluation:"
      ],
      "metadata": {
        "id": "ymiaoPqiWtbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
        "\n",
        "chosen_model = logistic_regression\n",
        "evaluate_model(chosen_model, X_test, y_test)\n",
        "\n",
        "cv_scores = cross_val_score(chosen_model, X_scaled, y, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VpK7XxsSwul",
        "outputId": "17fc5da4-c3ec-49be-b1ac-ab89d721ae30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.970048309178744, Precision: 0.9288025889967637, Recall: 0.9695945945945946, F1-score: 0.9487603305785124\n",
            "Cross-validation scores: [0.95652174 0.96714976 0.96324952 0.96034816 0.94970986]\n",
            "Mean CV accuracy: 0.9593958082209701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ensemble Methods"
      ],
      "metadata": {
        "id": "vaEEI8bbWxTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "\n",
        "ensemble_models = [random_forest, gradient_boosting]\n",
        "for model in ensemble_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    print(f\"{model.__class__.__name__} Accuracy: {accuracy}\")\n",
        "\n",
        "chosen_ensemble_model = gradient_boosting\n",
        "evaluate_model(chosen_ensemble_model, X_test, y_test)\n",
        "\n",
        "cv_scores_ensemble = cross_val_score(chosen_ensemble_model, X_scaled, y, cv=5)\n",
        "print(\"Cross-validation scores for ensemble model:\", cv_scores_ensemble)\n",
        "print(\"Mean CV accuracy for ensemble model:\", cv_scores_ensemble.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "063RPrFlW4Xl",
        "outputId": "a2cbc002-a1fa-42de-9c7b-5b8c290ed3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier Accuracy: 0.9710144927536232\n",
            "GradientBoostingClassifier Accuracy: 0.9719806763285024\n",
            "Accuracy: 0.9719806763285024, Precision: 0.9435215946843853, Recall: 0.9594594594594594, F1-score: 0.9514237855946398\n",
            "Cross-validation scores for ensemble model: [0.95362319 0.96328502 0.95551257 0.96711799 0.94003868]\n",
            "Mean CV accuracy for ensemble model: 0.9559154916416711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###HyperParameter_Tuning_of_Model"
      ],
      "metadata": {
        "id": "4G5h8R-XZ-n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
      ],
      "metadata": {
        "id": "aRVTx0mpZ_Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search for Logistic Regression\n",
        "param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                 'max_iter': [100, 200, 300, 400, 500, 1000]}\n",
        "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5)\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "best_lr = grid_search_lr.best_estimator_\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Logistic Regression (Grid Search) Evaluation:\")\n",
        "evaluate_model(best_lr, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FtC7uxozi5M",
        "outputId": "1c0a0c31-7733-451c-e3da-e4cf5b2ccf23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (Grid Search) Evaluation:\n",
            "Accuracy: 0.9806763285024155, Precision: 0.9630872483221476, Recall: 0.9695945945945946, F1-score: 0.9663299663299664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search for Random Forest\n",
        "param_grid_rf = {'n_estimators': [100, 200, 300],\n",
        "                 'max_depth': [10, 20, 30, None],\n",
        "                 'min_samples_split': [2, 5, 10],\n",
        "                 'min_samples_leaf': [1, 2, 4]}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "\n",
        "print(\"Random Forest (Grid Search) Evaluation:\")\n",
        "evaluate_model(best_rf, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQoonUgKz3Cp",
        "outputId": "1d95f28d-5f2b-4461-a6b1-803e4b6f6cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Grid Search) Evaluation:\n",
            "Accuracy: 0.9758454106280193, Precision: 0.9531772575250836, Recall: 0.9628378378378378, F1-score: 0.9579831932773111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Search for Random Forest\n",
        "param_dist_rf = {'n_estimators': [100, 200, 300],\n",
        "                 'max_depth': [10, 20, 30, None],\n",
        "                 'min_samples_split': [2, 5, 10],\n",
        "                 'min_samples_leaf': [1, 2, 4]}\n",
        "random_search_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist_rf, n_iter=10, cv=5)\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "best_rf_random = random_search_rf.best_estimator_\n",
        "\n",
        "print(\"Random Forest (Random Search) Evaluation:\")\n",
        "evaluate_model(best_rf_random, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc1nCtxozYfw",
        "outputId": "80ec935d-d837-415c-ee38-00ec37444f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (Random Search) Evaluation:\n",
            "Accuracy: 0.9768115942028985, Precision: 0.9563758389261745, Recall: 0.9628378378378378, F1-score: 0.9595959595959596\n"
          ]
        }
      ]
    }
  ]
}